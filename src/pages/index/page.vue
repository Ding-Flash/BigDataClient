<template>
  <d2-container>
    <template slot="header">
      大数据性能评测软件
    </template>
    <el-row :gutter="20">
      <el-col :span="24">
        <el-card>
            <div slot="header">
              <span>BigRoot模块介绍</span>
            </div>
            <div>
                <li>该模块着眼于应用层面进行分析，应用层面的性能问题主要是同一个阶段中产生的慢任务，其他运行较快的任务必须等待执行时间最长的任务运行完毕才能进入下一个阶段。</li>
                <li>本模块选择被广泛采用的系统特征，包括CPU、I/O、网络流量等资源占用特征以及数据局部性、读写数据量、混洗读写数据量、JVM垃圾收集时间、任务序列化和反序列化时间等应用特征。</li>
                <li>使用Linux采样工具收集系统资源占用信息，采样工具会在Spark启动的时候，自动在集群开始采样，记录采样开始时间戳，每秒钟搜集一次系统资源占用信息，写入日志，当Spark应用程序结束运行的时候，调度器在集群各个节点上杀死采样进程，然后聚合集群各个节点的采样日志，通过和Spark任务执行时间进行对比，就可以得到任务运行时的资源占用情况。</li>
                <li>应用特征则是从Spark日志文件中抽取的，反映了慢任务产生的内部原因，如数据倾斜，数据局部性、JVM垃圾搜集、任务序列化和反序列化、数据本地性等。采用以上种种特征，运用数学统计的方法，找出根原因影响程序运行的规律，从而反向推算根原因出现的时刻。</li>
            </div>
        </el-card>
      </el-col>
    </el-row>
      <br>
    <el-row>
      <el-col :span="24">
        <el-card>
            <div slot="header">
              <span>SparkTree模块介绍</span>
            </div>
            <div>
                <li>SparkOT是面向Standalone模式运行的Saprk大数据应用程序的性能数据采集、性能瓶颈挖掘分析以及性能数据可视化展示的程序模块。旨在面向Spark大数据程序开发人员，提供程序运行时的各层系统性能轨迹、程序运行时事件、Straggler瓶颈任务的检测分析以及性能热点算子的检测分析服务。</li>
                <li>该模块的主要功能包括Spark程序探针插桩、运行时环境性能数据采样、运行时Spark程序性能事件采集、性能数据收集与处理、性能瓶颈挖掘分析以及离线可视化性能轨迹展示。</li>
                <li>本模块依据Spark程序性能分析方法不同阶段，分解为四个主要功能模块，分别为性能数据采集模块、性能数据收集与处理模块、性能分析模块以及可视化模块。</li>
            </div>
        </el-card>
      </el-col>
    </el-row>
    <br>
    <el-row :gutter="20">
      <el-col :span="24">
        <el-card>
            <div slot="header">
              <span>ASTracer功能介绍</span>
            </div>
            <div>
                <li>ASTracer模块重点分析分布式文件系统内部的低效行为，这些性能信息在应用层面和框架层面的性能分析中都无法获取，但是分布式文件系统对所有的大数据系统都是至关重要的，这是大数据应用程序区别于高性能程序的一个重要特点。</li>
                <li>分布式文件系统的性能和应用层面、框架层面的性能息息相关，应用层面的数据倾斜和框架层面的HadoopRDD算子都和分布式文件系统性能紧密相关。</li>
                <li>对HDFS进行性能分析必须还原每一个I/O请求的函数调用树，否则便无法分析HDFS消耗在各个函数的延迟，定位造成性能瓶颈的高延迟函数，对分布式文件系统的插桩不能采用动态插桩，只能采用静态插桩的方式（直接修改源代码并进行编译）。</li>
                <li>在获取性能日志文件之后，首先需要将日志利用父子关系还原成多个调用树结构，这些树结构规模十分庞大，不便于分析，因此需要采用一种同构树压缩的算法进行大规模压缩。在进行压缩之后，还可以对压缩节点的数据进行规约，比如只保留函数执行时间的均值、方差、极值、分位点等统计信息。经过压缩后不仅数据规模大幅下降，同时也方便抽取典型I/O模式以及每种I/O模式下的性能瓶颈。</li>
            </div>
        </el-card>
      </el-col>
    </el-row>
  </d2-container>
</template>

<script>
  export default {
    data() {
      return {

      }
    },
    methods: {

    }
  }
</script>

<style lang="scss" scoped>

</style>
